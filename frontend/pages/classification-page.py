import streamlit as st
import torch
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
import zipfile
import json
from io import BytesIO
from datetime import datetime
from classify_utils import *

st.markdown(
    """
    <style>
    /* horizontally centered */
    .block-container {
        max-width: 1100px;        /* max width */
        margin: 0 auto;           /* auto center */
        padding-top: 1rem;
        padding-bottom: 1rem;
    }

    /* prevent sidebar squeezing the content */
    [data-testid="stSidebar"] {
        z-index: 1;
    }
    
    /* Keep default background, just style text */
    .stApp {
        color: black;
    }
    
    /* è®¾ç½®ä¸»è¦æ–‡å­—é¢œè‰²ä¸ºç™½è‰² */
    .stMarkdown, .stText, .stSelectbox, .stTextInput, .stTextArea, .stNumberInput {
        color: black !important;
    }
    
    /* è®¾ç½®æ ‡é¢˜é¢œè‰²ä¸ºç™½è‰² */
    h1, h2, h3, h4, h5, h6 {
        color: black !important;
    }
    
    /* è®¾ç½®æ®µè½å’Œæ–‡æœ¬é¢œè‰²ä¸ºç™½è‰² */
    p, div, span, label {
        color: black !important;
    }

    .stImage > div {
        transition: transform 0.3s ease, box-shadow 0.3s ease;
        border-radius: 15px;
        overflow: hidden;
    }
    
    .stImage > div:hover {
        transform: translateY(-5px) scale(1.02);
        box-shadow: 0 10px 25px rgba(0,0,0,0.2);
    }
    
    /* æŒ‰é’®æ‚¬åœæ•ˆæœ */
    .stButton > button {
        transition: all 0.3s ease;
        border-radius: 25px;
        background: linear-gradient(45deg, #1C3659, #5A7A9B);
        color: white;
        border: none;
        padding: 0.5rem 2rem;
        font-weight: bold;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(28, 54, 89, 0.4);
    }
    
    /* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸæ‚¬åœæ•ˆæœ */
    .stFileUploader > div {
        transition: all 0.3s ease;
        border-radius: 10px;
    }
    
    .stFileUploader > div:hover {
        transform: scale(1.02);
        box-shadow: 0 5px 15px rgba(28, 54, 89, 0.2);
    }

    /* æ ‡ç­¾é¡µæ‚¬åœæ•ˆæœ */
    .stTabs [data-baseweb="tab"] {
        transition: all 0.3s ease;
        border-radius: 20px;
        padding: 8px 16px;
        margin: 2px;
    }
    
    .stTabs [data-baseweb="tab"]:hover {
        background: linear-gradient(45deg, rgba(28, 54, 89, 0.8), rgba(90, 122, 155, 0.8));
        color: white !important;
        transform: scale(1.05);
        box-shadow: 0 4px 12px rgba(28, 54, 89, 0.3);
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(45deg, #1C3659, #5A7A9B);
        color: white !important;
        box-shadow: 0 2px 8px rgba(28, 54, 89, 0.4);
    }

    </style>
""", unsafe_allow_html=True)

st.set_page_config(page_title="Benthic Species Classification", layout="wide")

def create_softmax_chart(probs_dict, prediction, confidence):
    """åˆ›å»ºsoftmaxæ¦‚ç‡æŸ±çŠ¶å›¾"""
    # æŒ‰æ¦‚ç‡æ’åº
    sorted_probs = sorted(probs_dict.items(), key=lambda x: x[1], reverse=True)
    labels = [item[0] for item in sorted_probs]
    values = [item[1] for item in sorted_probs]
    
    # åˆ›å»ºé¢œè‰²æ˜ å°„ï¼Œé¢„æµ‹ç»“æœç”¨ç‰¹æ®Šé¢œè‰²
    colors = ['#FF6B6B' if label == prediction else '#4ECDC4' for label in labels]
    
    # åˆ›å»ºå›¾è¡¨
    fig, ax = plt.subplots(figsize=(10, 6))
    bars = ax.bar(range(len(labels)), values, color=colors, alpha=0.8, edgecolor='white', linewidth=1)
    
    # è®¾ç½®æ ‡ç­¾
    ax.set_xlabel('Species', fontsize=12, fontweight='bold')
    ax.set_ylabel('Probability', fontsize=12, fontweight='bold')
    ax.set_title(f'Classification Results\nPredicted: {prediction} (Confidence: {confidence:.2%})', 
                fontsize=14, fontweight='bold', pad=20)
    
    # è®¾ç½®xè½´æ ‡ç­¾
    ax.set_xticks(range(len(labels)))
    ax.set_xticklabels(labels, rotation=45, ha='right')
    
    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, value) in enumerate(zip(bars, values)):
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{value:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    # è®¾ç½®yè½´èŒƒå›´
    ax.set_ylim(0, max(values) * 1.2)
    
    # æ·»åŠ ç½‘æ ¼
    ax.grid(True, alpha=0.3, axis='y')
    
    # è®¾ç½®èƒŒæ™¯è‰²
    ax.set_facecolor('#f8f9fa')
    fig.patch.set_facecolor('white')
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout()
    
    return fig

def save_feedback(prediction, confidence, user_correction, feedback_type, image_name):
    """ä¿å­˜ç”¨æˆ·åé¦ˆæ•°æ®"""
    feedback_data = {
        'timestamp': datetime.now().isoformat(),
        'image_name': image_name,
        'predicted_class': prediction,
        'confidence': confidence,
        'user_correction': user_correction,
        'feedback_type': feedback_type  # 'correct' or 'incorrect'
    }
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    feedback_file = 'feedback_data.json'
    if os.path.exists(feedback_file):
        with open(feedback_file, 'r') as f:
            feedbacks = json.load(f)
    else:
        feedbacks = []
    
    feedbacks.append(feedback_data)
    
    with open(feedback_file, 'w') as f:
        json.dump(feedbacks, f, indent=2)
    
    return True

def load_feedback_data():
    """åŠ è½½åé¦ˆæ•°æ®"""
    feedback_file = 'feedback_data.json'
    if os.path.exists(feedback_file):
        with open(feedback_file, 'r') as f:
            return json.load(f)
    return []

def create_feedback_interface(image, prediction, confidence, image_name):
    """åˆ›å»ºåé¦ˆç•Œé¢"""
    st.markdown("---")
    st.markdown("### ğŸ“ Feedback System")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.write("**Is the prediction correct?**")
        feedback_type = st.radio(
            "Please select:",
            ["âœ… Correct", "âŒ Incorrect"],
            key=f"feedback_{image_name}",
            horizontal=True
        )
    
    with col2:
        if feedback_type == "âŒ Incorrect":
            st.write("**Please select the correct classification:**")
            correct_class = st.selectbox(
                "Correct classification:",
                ["Eel", "Scallop", "crab", "flatfish", "roundfish", "skate", "whelk"],
                key=f"correction_{image_name}"
            )
        else:
            correct_class = prediction
    
    # æäº¤åé¦ˆæŒ‰é’®
    if st.button(f"æäº¤åé¦ˆ", key=f"submit_{image_name}"):
        # ä¿å­˜åé¦ˆ
        success = save_feedback(
            prediction, 
            confidence, 
            correct_class, 
            "correct" if feedback_type == "âœ… Correct" else "incorrect",
            image_name
        )
        
        if success:
            st.success("âœ… Feedback saved!")
            st.rerun()
        else:       
            st.error("âŒ Failed to save feedback, please try again")
    
    return feedback_type, correct_class if feedback_type == "âŒ Incorrect" else prediction

def process_batch_images(images, model, processor, progress_bar=None):
    """æ‰¹é‡å¤„ç†å›¾ç‰‡å¹¶è¿”å›ç»“æœ"""
    results = []
    
    for i, (filename, image) in enumerate(images):
        try:
            # é¢„æµ‹
            result = classify_image_with_probs(image, model, processor)
            result['filename'] = filename
            result['status'] = 'success'
            results.append(result)
            
            # æ›´æ–°è¿›åº¦æ¡
            if progress_bar:
                progress_bar.progress((i + 1) / len(images))
                
        except Exception as e:
            results.append({
                'filename': filename,
                'prediction': 'Error',
                'confidence': 0.0,
                'all_probs': {},
                'status': 'error',
                'error': str(e)
            })
    
    return results

def create_batch_report(results):
    """åˆ›å»ºæ‰¹é‡é¢„æµ‹æŠ¥å‘Š"""
    # åˆ›å»ºDataFrame
    df_data = []
    for result in results:
        if result['status'] == 'success':
            df_data.append({
                'Filename': result['filename'],
                'Prediction': result['prediction'],
                'Confidence': f"{result['confidence']:.2%}",
                'Status': 'Success'
            })
        else:
            df_data.append({
                'Filename': result['filename'],
                'Prediction': 'Error',
                'Confidence': 'N/A',
                'Status': 'Error'
            })
    
    df = pd.DataFrame(df_data)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_images = len(results)
    successful = len([r for r in results if r['status'] == 'success'])
    failed = total_images - successful
    
    # é¢„æµ‹åˆ†å¸ƒ
    if successful > 0:
        predictions = [r['prediction'] for r in results if r['status'] == 'success']
        pred_counts = pd.Series(predictions).value_counts()
    else:
        pred_counts = pd.Series()
    
    return df, total_images, successful, failed, pred_counts

def create_batch_summary_chart(pred_counts):
    """åˆ›å»ºæ‰¹é‡é¢„æµ‹æ±‡æ€»å›¾è¡¨"""
    if len(pred_counts) == 0:
        return None
    
    fig, ax = plt.subplots(figsize=(10, 6))
    bars = ax.bar(pred_counts.index, pred_counts.values, color='#4ECDC4', alpha=0.8)
    
    ax.set_xlabel('Species', fontsize=12, fontweight='bold')
    ax.set_ylabel('Count', fontsize=12, fontweight='bold')
    ax.set_title('Batch Prediction Summary', fontsize=14, fontweight='bold')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{int(height)}', ha='center', va='bottom', fontweight='bold')
    
    plt.xticks(rotation=45)
    plt.tight_layout()
    return fig

# Page title
st.markdown(
    "<h1 style='text-align: center; font-size: 40px;'>ViT Image Classifier</h1>",
    unsafe_allow_html=True
)

st.markdown(
    "<p style='text-align:center; color:gray; font-size:16px;'>"
    "â˜… Upload images to classify benthic species using Vision Transformer (ViT). â˜…"
    "</p>",
    unsafe_allow_html=True
)

# Load model
model, processor, load_msg = load_vit_model()

tab1, tab2, tab3, tab4 = st.tabs(["Single Image", "Camera", "Batch Upload", "Feedback Management"])

with tab1:
    st.markdown(
        """
        <h4 style='text-align: left; font-weight: 600; font-size: 16px; margin-top: 0px;'>
            Upload Images for Classification:
        </h4>
        """,
        unsafe_allow_html=True
    )
    files = st.file_uploader("", type=["png", "jpg", "jpeg"], accept_multiple_files=True, label_visibility="collapsed")
    if files:
        for f in files:
            image = Image.open(f).convert("RGB")
            
            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.image(image, caption=f.name, width=300)
            
            with col2:
                with st.spinner("Predicting..."):
                    # è·å–è¯¦ç»†é¢„æµ‹ç»“æœ
                    result = classify_image_with_probs(image, model, processor)
                
                # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
                st.success(f"ğŸ¯ **Prediction:** {result['prediction']}")
                st.info(f"ğŸ“Š **Confidence:** {result['confidence']:.2%}")
                
                # åˆ›å»ºå¹¶æ˜¾ç¤ºsoftmaxå›¾
                fig = create_softmax_chart(result['all_probs'], result['prediction'], result['confidence'])
                st.pyplot(fig)
                
                # æ·»åŠ åé¦ˆç³»ç»Ÿ
                create_feedback_interface(image, result['prediction'], result['confidence'], f.name)
            
            st.markdown("---")

with tab2:
    st.markdown(
        """
        <h4 style='text-align: left; font-weight: 600; font-size: 16px; margin-top: 0px;'>
            Take a Photo for Classification:
        </h4>
        """,
        unsafe_allow_html=True
    )
    cam = st.camera_input("", label_visibility="collapsed")
    if cam is not None:
        image = Image.open(cam).convert("RGB")
        
        # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.image(image, caption="Camera Photo", width=300)
        
        with col2:
            with st.spinner("Predicting..."):
                # è·å–è¯¦ç»†é¢„æµ‹ç»“æœ
                result = classify_image_with_probs(image, model, processor)
            
            # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
            st.success(f"ğŸ¯ **Prediction:** {result['prediction']}")
            st.info(f"ğŸ“Š **Confidence:** {result['confidence']:.2%}")
            
            # åˆ›å»ºå¹¶æ˜¾ç¤ºsoftmaxå›¾
            fig = create_softmax_chart(result['all_probs'], result['prediction'], result['confidence'])
            st.pyplot(fig)
            
            # æ·»åŠ åé¦ˆç³»ç»Ÿ
            create_feedback_interface(image, result['prediction'], result['confidence'], "camera_photo")
        
        st.markdown("---")

with tab3:
    st.markdown(
        """
        <h4 style='text-align: left; font-weight: 600; font-size: 16px; margin-top: 0px;'>
            ğŸ“ Batch Image Upload
        </h4>
        """,
        unsafe_allow_html=True
    )
    st.write("Upload multiple images at once to get a comprehensive prediction report.")
    
    # ä¸Šä¼ æ–¹å¼é€‰æ‹©
    upload_method = st.radio(
        "Choose upload method:",
        ["Upload Folder (ZIP)", "Upload Multiple Files"],
        horizontal=True
    )
    
    uploaded_files = []
    
    if upload_method == "Upload Multiple Files":
        # å¤šæ–‡ä»¶ä¸Šä¼ 
        uploaded_files = st.file_uploader(
            "Choose multiple images", 
            type=["png", "jpg", "jpeg"], 
            accept_multiple_files=True,
            help="Select multiple images to process in batch"
        )
    
    else:
        # ZIPæ–‡ä»¶å¤¹ä¸Šä¼ 
        zip_file = st.file_uploader(
            "Upload a folder (ZIP file) containing images",
            type=["zip"],
            help="Compress your image folder into a ZIP file and upload it. All images in the folder will be processed automatically. (Ignores __MACOSX and hidden files)"
        )
        
        if zip_file is not None:
            try:
                # æå–ZIPæ–‡ä»¶
                with zipfile.ZipFile(zip_file, 'r') as zip_ref:
                    # è·å–ZIPä¸­çš„æ‰€æœ‰æ–‡ä»¶
                    file_list = zip_ref.namelist()
                    
                    # è¿‡æ»¤æ‰__MACOSXæ–‡ä»¶å¤¹å’Œéšè—æ–‡ä»¶
                    filtered_files = []
                    for f in file_list:
                        # å¿½ç•¥__MACOSXæ–‡ä»¶å¤¹ã€éšè—æ–‡ä»¶å’Œç›®å½•
                        if (not f.startswith('__MACOSX/') and 
                            not f.startswith('.') and 
                            not f.endswith('/') and
                            not f.startswith('Thumbs.db')):
                            filtered_files.append(f)
                    
                    # è¿‡æ»¤å‡ºå›¾ç‰‡æ–‡ä»¶
                    image_extensions = ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']
                    image_files = [f for f in filtered_files if any(f.lower().endswith(ext) for ext in image_extensions)]
                    
                    if image_files:
                        total_files = len(file_list)
                        filtered_count = len(filtered_files)
                        st.success(f"Found {len(image_files)} images in the ZIP file")
                        st.info(f"ğŸ“Š Processed {total_files} total files, filtered to {filtered_count} valid files, found {len(image_files)} images")
                        
                        # æ˜¾ç¤ºå›¾ç‰‡åˆ—è¡¨é¢„è§ˆ
                        with st.expander("ğŸ“‹ Preview images in folder"):
                            for i, img_file in enumerate(image_files[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
                                st.write(f"{i+1}. {img_file}")
                            if len(image_files) > 10:
                                st.write(f"... and {len(image_files) - 10} more images")
                        
                        # åˆ›å»ºè™šæ‹Ÿæ–‡ä»¶å¯¹è±¡
                        class VirtualFile:
                            def __init__(self, name, data):
                                self.name = name
                                self.data = data
                            
                            def read(self):
                                return self.data
                        
                        # æå–å›¾ç‰‡å¹¶åˆ›å»ºè™šæ‹Ÿæ–‡ä»¶å¯¹è±¡
                        for img_file in image_files:
                            try:
                                img_data = zip_ref.read(img_file)
                                virtual_file = VirtualFile(img_file, img_data)
                                uploaded_files.append(virtual_file)
                            except Exception as e:
                                st.warning(f"Could not extract {img_file}: {str(e)}")
                    else:
                        st.error("No image files found in the ZIP file. Please ensure the ZIP contains PNG, JPG, or JPEG files.")
                        
            except Exception as e:
                st.error(f"Error processing ZIP file: {str(e)}")
                uploaded_files = []
    
    if uploaded_files:
        st.info(f"ğŸ“Š **{len(uploaded_files)} images** selected for batch processing")
        
        # å¤„ç†é€‰é¡¹
        col1, col2 = st.columns([1, 1])
        with col1:
            show_individual = st.checkbox("Show individual results", value=True)
        with col2:
            download_report = st.checkbox("Download report as CSV", value=True)
        
        if st.button("ğŸš€ Start Batch Processing", type="primary"):
            # å‡†å¤‡å›¾ç‰‡æ•°æ®
            images = []
            for file in uploaded_files:
                try:
                    # å¤„ç†è™šæ‹Ÿæ–‡ä»¶å¯¹è±¡å’Œæ™®é€šæ–‡ä»¶å¯¹è±¡
                    if hasattr(file, 'read'):
                        if hasattr(file, 'data'):  # è™šæ‹Ÿæ–‡ä»¶å¯¹è±¡
                            image = Image.open(BytesIO(file.data)).convert("RGB")
                        else:  # æ™®é€šæ–‡ä»¶å¯¹è±¡
                            image = Image.open(file).convert("RGB")
                    else:
                        st.error(f"Invalid file object: {file.name}")
                        continue
                    
                    images.append((file.name, image))
                except Exception as e:
                    st.error(f"Error loading {file.name}: {str(e)}")
            
            if images:
                # åˆ›å»ºè¿›åº¦æ¡
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # æ‰¹é‡å¤„ç†
                status_text.text("ğŸ”„ Processing images...")
                results = process_batch_images(images, model, processor, progress_bar)
                
                # ç”ŸæˆæŠ¥å‘Š
                status_text.text("ğŸ“Š Generating report...")
                df, total, successful, failed, pred_counts = create_batch_report(results)
                
                # æ˜¾ç¤ºç»“æœ
                st.success(f"âœ… Batch processing completed! {successful}/{total} images processed successfully")
                
                # ç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Total Images", total)
                with col2:
                    st.metric("Successful", successful)
                with col3:
                    st.metric("Failed", failed)
                with col4:
                    success_rate = (successful / total * 100) if total > 0 else 0
                    st.metric("Success Rate", f"{success_rate:.1f}%")
                
                # é¢„æµ‹åˆ†å¸ƒå›¾è¡¨
                if len(pred_counts) > 0:
                    st.subheader("ğŸ“ˆ Prediction Distribution")
                    summary_chart = create_batch_summary_chart(pred_counts)
                    if summary_chart:
                        st.pyplot(summary_chart)
                    
                    # è¯¦ç»†ç§ç±»ç»Ÿè®¡
                    st.subheader("ğŸ“Š Species Statistics")
                    species_stats = []
                    for species, count in pred_counts.items():
                        percentage = (count / successful * 100) if successful > 0 else 0
                        species_stats.append({
                            'Species': species,
                            'Count': count,
                            'Percentage': f"{percentage:.1f}%"
                        })
                    
                    # åˆ›å»ºç»Ÿè®¡è¡¨æ ¼
                    stats_df = pd.DataFrame(species_stats)
                    st.dataframe(stats_df, use_container_width=True)
                    
                    # æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Most Common", pred_counts.index[0], f"{pred_counts.iloc[0]} images")
                    with col2:
                        if len(pred_counts) > 1:
                            st.metric("Second Most", pred_counts.index[1], f"{pred_counts.iloc[1]} images")
                        else:
                            st.metric("Second Most", "N/A", "0 images")
                    with col3:
                        diversity = len(pred_counts)
                        st.metric("Species Diversity", f"{diversity} species", f"out of 7 possible")
                
                # è¯¦ç»†ç»“æœè¡¨æ ¼
                st.subheader("ğŸ“‹ Detailed Results")
                st.dataframe(df, use_container_width=True)
                
                # ä¸‹è½½æŠ¥å‘Š
                if download_report:
                    # åˆ›å»ºCSV
                    csv = df.to_csv(index=False)
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"benthic_predictions_{timestamp}.csv"
                    
                    # åˆ›å»ºåŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å®Œæ•´æŠ¥å‘Š
                    report_sections = []
                    
                    # 1. æ€»ä½“ç»Ÿè®¡
                    report_sections.append("=== BENTHIC SPECIES CLASSIFICATION REPORT ===")
                    report_sections.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                    report_sections.append(f"Total Images: {total}")
                    report_sections.append(f"Successfully Processed: {successful}")
                    report_sections.append(f"Failed: {failed}")
                    report_sections.append(f"Success Rate: {success_rate:.1f}%")
                    report_sections.append("")
                    
                    # 2. ç§ç±»ç»Ÿè®¡
                    if len(pred_counts) > 0:
                        report_sections.append("=== SPECIES STATISTICS ===")
                        for species, count in pred_counts.items():
                            percentage = (count / successful * 100) if successful > 0 else 0
                            report_sections.append(f"{species}: {count} images ({percentage:.1f}%)")
                        report_sections.append("")
                    
                    # 3. è¯¦ç»†ç»“æœ
                    report_sections.append("=== DETAILED RESULTS ===")
                    report_sections.append(csv)
                    
                    # åˆå¹¶æŠ¥å‘Š
                    full_report = "\n".join(report_sections)
                    
                    st.download_button(
                        label="ğŸ“¥ Download Complete Report (CSV)",
                        data=full_report,
                        file_name=filename,
                        mime="text/csv"
                    )
                
                # æ˜¾ç¤ºä¸ªåˆ«ç»“æœï¼ˆå¯é€‰ï¼‰
                if show_individual:
                    st.subheader("ğŸ–¼ï¸ Individual Results")
                    for i, result in enumerate(results):
                        if result['status'] == 'success':
                            with st.expander(f"ğŸ“¸ {result['filename']} - {result['prediction']}"):
                                col1, col2 = st.columns([1, 1])
                                with col1:
                                    # æ˜¾ç¤ºå›¾ç‰‡ï¼ˆéœ€è¦é‡æ–°åŠ è½½ï¼‰
                                    for file in uploaded_files:
                                        if file.name == result['filename']:
                                            try:
                                                if hasattr(file, 'data'):  # è™šæ‹Ÿæ–‡ä»¶å¯¹è±¡
                                                    image = Image.open(BytesIO(file.data)).convert("RGB")
                                                else:  # æ™®é€šæ–‡ä»¶å¯¹è±¡
                                                    image = Image.open(file).convert("RGB")
                                                st.image(image, width=200)
                                            except Exception as e:
                                                st.error(f"Could not display image: {str(e)}")
                                            break
                                with col2:
                                    st.success(f"**Prediction:** {result['prediction']}")
                                    st.info(f"**Confidence:** {result['confidence']:.2%}")
                                    
                                    # æ˜¾ç¤ºsoftmaxå›¾
                                    if result['all_probs']:
                                        fig = create_softmax_chart(result['all_probs'], result['prediction'], result['confidence'])
                                        st.pyplot(fig)
                        else:
                            st.error(f"âŒ {result['filename']}: {result.get('error', 'Unknown error')}")

with tab4:
    st.markdown(
        """
        <h4 style='text-align: left; font-weight: 600; font-size: 16px; margin-top: 0px;'>
            ğŸ“Š åé¦ˆæ•°æ®ç®¡ç†
        </h4>
        """,
        unsafe_allow_html=True
    )
    st.write("æŸ¥çœ‹å’Œç®¡ç†ç”¨æˆ·åé¦ˆæ•°æ®ï¼Œç”Ÿæˆå¼ºåŒ–å­¦ä¹ æ•°æ®é›†")
    
    # åŠ è½½åé¦ˆæ•°æ®
    feedbacks = load_feedback_data()
    
    if not feedbacks:
        st.info("ğŸ“ æš‚æ— åé¦ˆæ•°æ®ã€‚è¯·å…ˆä½¿ç”¨åˆ†ç±»åŠŸèƒ½å¹¶æäº¤åé¦ˆã€‚")
    else:
        st.success(f"ğŸ“Š å…±æ”¶é›†åˆ° {len(feedbacks)} æ¡åé¦ˆæ•°æ®")
        
        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3, col4 = st.columns(4)
        
        correct_count = len([f for f in feedbacks if f['feedback_type'] == 'correct'])
        incorrect_count = len([f for f in feedbacks if f['feedback_type'] == 'incorrect'])
        
        with col1:
            st.metric("æ€»åé¦ˆæ•°", len(feedbacks))
        with col2:
            st.metric("æ­£ç¡®é¢„æµ‹", correct_count)
        with col3:
            st.metric("é”™è¯¯é¢„æµ‹", incorrect_count)
        with col4:
            accuracy = (correct_count / len(feedbacks) * 100) if feedbacks else 0
            st.metric("ç”¨æˆ·ç¡®è®¤å‡†ç¡®ç‡", f"{accuracy:.1f}%")
        
        # é”™è¯¯é¢„æµ‹åˆ†æ
        if incorrect_count > 0:
            st.subheader("ğŸ” é”™è¯¯é¢„æµ‹åˆ†æ")
            
            # æŒ‰ç‰©ç§ç»Ÿè®¡é”™è¯¯
            error_by_species = {}
            for feedback in feedbacks:
                if feedback['feedback_type'] == 'incorrect':
                    predicted = feedback['predicted_class']
                    corrected = feedback['user_correction']
                    key = f"{predicted} â†’ {corrected}"
                    error_by_species[key] = error_by_species.get(key, 0) + 1
            
            if error_by_species:
                error_df = pd.DataFrame(list(error_by_species.items()), columns=['é”™è¯¯ç±»å‹', 'æ¬¡æ•°'])
                error_df = error_df.sort_values('æ¬¡æ•°', ascending=False)
                st.dataframe(error_df, use_container_width=True)
        
        # æ˜¾ç¤ºè¯¦ç»†åé¦ˆæ•°æ®
        st.subheader("ğŸ“‹ è¯¦ç»†åé¦ˆæ•°æ®")
        
        # åˆ›å»ºDataFrame
        display_data = []
        for i, feedback in enumerate(feedbacks):
            display_data.append({
                'åºå·': i + 1,
                'æ—¶é—´': feedback['timestamp'][:19],
                'å›¾ç‰‡åç§°': feedback['image_name'],
                'é¢„æµ‹ç»“æœ': feedback['predicted_class'],
                'ç½®ä¿¡åº¦': f"{feedback['confidence']:.2%}",
                'ç”¨æˆ·ä¿®æ­£': feedback['user_correction'],
                'çŠ¶æ€': 'âœ… æ­£ç¡®' if feedback['feedback_type'] == 'correct' else 'âŒ é”™è¯¯'
            })
        
        df = pd.DataFrame(display_data)
        st.dataframe(df, use_container_width=True)
        
        # ç”Ÿæˆå¼ºåŒ–æ•°æ®é›†
        st.subheader("ğŸ¯ ç”Ÿæˆå¼ºåŒ–æ•°æ®é›†")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            if st.button("ğŸ“¥ å¯¼å‡ºé”™è¯¯é¢„æµ‹æ•°æ®é›†", type="primary"):
                # åªå¯¼å‡ºé”™è¯¯é¢„æµ‹çš„æ•°æ®
                error_feedbacks = [f for f in feedbacks if f['feedback_type'] == 'incorrect']
                
                if error_feedbacks:
                    # åˆ›å»ºå¼ºåŒ–å­¦ä¹ æ•°æ®é›†
                    reinforcement_data = []
                    for feedback in error_feedbacks:
                        reinforcement_data.append({
                            'image_name': feedback['image_name'],
                            'true_label': feedback['user_correction'],
                            'predicted_label': feedback['predicted_class'],
                            'confidence': feedback['confidence'],
                            'timestamp': feedback['timestamp']
                        })
                    
                    # ä¿å­˜ä¸ºJSON
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"reinforcement_dataset_{timestamp}.json"
                    
                    with open(filename, 'w') as f:
                        json.dump(reinforcement_data, f, indent=2)
                    
                    st.success(f"âœ… å¼ºåŒ–æ•°æ®é›†å·²å¯¼å‡º: {filename}")
                    st.info(f"ğŸ“Š åŒ…å« {len(reinforcement_data)} æ¡é”™è¯¯é¢„æµ‹æ•°æ®")
                else:
                    st.warning("âš ï¸ æš‚æ— é”™è¯¯é¢„æµ‹æ•°æ®å¯å¯¼å‡º")
        
        with col2:
            if st.button("ğŸ“Š å¯¼å‡ºå®Œæ•´åé¦ˆæ•°æ®"):
                # å¯¼å‡ºæ‰€æœ‰åé¦ˆæ•°æ®
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"complete_feedback_{timestamp}.json"
                
                with open(filename, 'w') as f:
                    json.dump(feedbacks, f, indent=2)
                
                st.success(f"âœ… å®Œæ•´åé¦ˆæ•°æ®å·²å¯¼å‡º: {filename}")
        
        # æ•°æ®æ¸…ç†
        st.subheader("ğŸ§¹ æ•°æ®ç®¡ç†")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰åé¦ˆæ•°æ®", type="secondary"):
                if os.path.exists('feedback_data.json'):
                    os.remove('feedback_data.json')
                    st.success("âœ… åé¦ˆæ•°æ®å·²æ¸…ç©º")
                    st.rerun()
        
        with col2:
            if st.button("ğŸ”„ åˆ·æ–°æ•°æ®"):
                st.rerun()
        
        # æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡å›¾è¡¨
        if len(feedbacks) > 0:
            st.subheader("ğŸ“ˆ åé¦ˆæ•°æ®ç»Ÿè®¡")
            
            # æŒ‰æ—¶é—´ç»Ÿè®¡
            dates = [f['timestamp'][:10] for f in feedbacks]
            date_counts = pd.Series(dates).value_counts().sort_index()
            
            fig, ax = plt.subplots(figsize=(10, 4))
            ax.plot(date_counts.index, date_counts.values, marker='o')
            ax.set_title('æ¯æ—¥åé¦ˆæ•°é‡')
            ax.set_xlabel('æ—¥æœŸ')
            ax.set_ylabel('åé¦ˆæ•°é‡')
            plt.xticks(rotation=45)
            plt.tight_layout()
            st.pyplot(fig)
